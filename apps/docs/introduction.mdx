---
title: Introduction
---

Welcome to EvalKit, the open-source library designed to help TypeScript developers evaluate and improve the performance of large language models (LLMs) with confidence.
EvalKit provides a suite of tools and evaluators to ensure your AI models are reliable, accurate, and trustworthy.

## Why EvalKit?

In the world of artificial intelligence, particularly with large language models, ensuring the quality and reliability of AI outputs is a significant challenge. Models can produce outputs that are coherent and relevant but still contain errors, biases, or inconsistencies. EvalKit addresses these challenges by offering robust evaluation tools.

## Key Features

- **Bias Detection**: Identify and mitigate biases in your models to ensure fairness.
- **Dynamic Evaluation (G Eval)**: Perform versatile evaluations based on custom criteria.
- **Coherence, Faithfulness, and More**: Assess various aspects of model performance with specialized evaluators.

By integrating EvalKit into your development workflow, you can ship AI solutions with confidence, knowing that your models are rigorously tested and evaluated.

## Getting Started

Explore the documentation to learn more about EvalKit's features and how to integrate them into your projects. Whether you're new to AI evaluations or an experienced developer, EvalKit offers the tools and insights you need to build better, more reliable AI systems.